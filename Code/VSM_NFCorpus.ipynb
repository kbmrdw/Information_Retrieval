{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Thư viện"
      ],
      "metadata": {
        "id": "gKVlrW8etFPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import bisect\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "ss = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "R4iZ0GNlLzJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "itkNnmKAvqHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd54bfdf-f1f5-4f97-d332-cb10f1c520a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NFCorpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk7tOZP6MD_M",
        "outputId": "ccd86a8c-a57f-4ba3-a00e-4c0ae2e2b659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NFCorpus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X20I-S3nMH1d",
        "outputId": "44516955-5f54-49f8-b416-aa612f241aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NF_docs  NF_qrel  NF_queries  test.2-1-0.qrel  test.all.queries  test.docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "Ymk-rP65wfB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d94432-9f2e-4dae-88fa-783e8a98d8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "PNYDQqyc0WtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiền xử lý"
      ],
      "metadata": {
        "id": "wulfkQt3HMNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    processed_text = text.lower()\n",
        "    processed_text = processed_text.replace(\"’\", \"'\")\n",
        "    processed_text = processed_text.replace(\"“\", '\"')\n",
        "    processed_text = processed_text.replace(\"”\", '\"')\n",
        "    non_words = re.compile(r\"[^A-Za-z']+\")\n",
        "    processed_text = re.sub(non_words, ' ', processed_text)\n",
        "    return processed_text"
      ],
      "metadata": {
        "id": "HhvCG-B7tdyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_from_text(text):\n",
        "    processed_text = preprocess_text(text)\n",
        "    filtered_words = [word for word in processed_text.split() if word not in stopwords.words('english')]\n",
        "    processed_words = []\n",
        "    for i in range(len(filtered_words)):\n",
        "        processed_words.append(lemmatizer.lemmatize(filtered_words[i]))\n",
        "        # processed_words.append(ps.stem(filtered_words[i]))\n",
        "    return processed_words"
      ],
      "metadata": {
        "id": "g2nUvQwHtfnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_from_file(filename):\n",
        "    with open(filename, encoding='utf-8', mode='r') as f:\n",
        "        text = f.read()\n",
        "    return text"
      ],
      "metadata": {
        "id": "o6YrHspztic7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexing(docs_path):\n",
        "    terms = []\n",
        "    index = []\n",
        "    norm_list = []\n",
        "    N = 0\n",
        "\n",
        "    # Indexing postings\n",
        "    for doc_file in sorted(os.listdir(docs_path),key=lambda x: int(os.path.splitext(x)[0])):\n",
        "        filename = os.path.join(docs_path, doc_file)\n",
        "        N += 1\n",
        "        text = get_text_from_file(filename)\n",
        "        words = get_words_from_text(text)\n",
        "        for word in words:\n",
        "            if word not in terms:\n",
        "                terms.append(word)\n",
        "                index.append([(N, 1)])\n",
        "            else:\n",
        "                temp_index = terms.index(word)\n",
        "                if N not in [i[0] for i in index[temp_index]]:\n",
        "                    index[temp_index].append((N, 1))\n",
        "                    continue\n",
        "                for i in range(len(index[temp_index])):\n",
        "                    if index[temp_index][i][0] == N:\n",
        "                        index[temp_index][i] = (N, index[temp_index][i][1] + 1)\n",
        "                        break\n",
        "\n",
        "    # Calculate weights\n",
        "    for i in range(len(index)):\n",
        "        for j in range(len(index[i])):\n",
        "            temp = list(index[i][j])\n",
        "            temp[1] = index[i][j][1] * math.log(N/len(index[i])+1) # Formula: TF * IDF (IDF = log(N / ndoc(t)))\n",
        "            index[i][j] = tuple(temp)\n",
        "\n",
        "    # Normalization\n",
        "    for i in range(N):\n",
        "        norm = 0\n",
        "        for j in range(len(index)):\n",
        "            temp = [item for item in index[j] if item[0] == i+1]\n",
        "            if len(temp) != 0:\n",
        "                norm += math.pow(temp[0][1], 2)\n",
        "        norm_list.append(math.sqrt(norm))\n",
        "    for i in range(len(index)):\n",
        "        for j in range(len(index[i])):\n",
        "            temp = list(index[i][j])\n",
        "            temp[1] = index[i][j][1] / norm_list[index[i][j][0]-1]\n",
        "            index[i][j] = tuple(temp)\n",
        "\n",
        "    return terms, index"
      ],
      "metadata": {
        "id": "mTJWHIf8MH8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms, index = indexing(r'./NF_docs')"
      ],
      "metadata": {
        "id": "-mDWm-lYvKVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(terms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oJKBQevvKvA",
        "outputId": "31761bb7-eb7e-46d3-bcb6-59bf053171e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(index[:2])"
      ],
      "metadata": {
        "id": "W7P35zqLvMYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32fce77-5671-4ecc-b6e5-db6399c0c4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(1, 0.7233587586213442), (2, 0.4109294221350846), (156, 0.30756026615496546), (168, 0.10333254993500658), (211, 0.12478749215457015), (230, 0.07175042715866932), (342, 0.07646633272836052), (391, 0.21854066586261967), (454, 0.06986466371799159), (528, 0.0488871183626622), (731, 0.07699466486799758), (741, 0.16756860328683065), (1163, 0.3618981031715568), (1164, 0.5610795333150008), (1166, 0.5650329266217543), (1167, 0.07699466486799758), (1230, 0.06519209599599779), (1623, 0.0930109541552868), (1745, 0.06677164749124415), (2597, 0.5521508019127087), (2806, 0.1182305020031857), (2808, 0.3994935516642588), (2809, 0.5038351991456685), (2810, 0.5142890852705635)], [(1, 0.25746168633368666), (2, 0.475345583861006), (11, 0.030023120259717356), (63, 0.16033847525289766), (65, 0.03187550302679276), (75, 0.0261294025699638), (122, 0.08425071000547192), (132, 0.03699120962576088), (144, 0.033017801359831664), (146, 0.030395990378806432), (185, 0.2612455820908789), (186, 0.04001412052637377), (292, 0.041226698925854004), (296, 0.057612357620207326), (392, 0.0585564418914437), (437, 0.2134040184975508), (462, 0.24582826049869713), (486, 0.03655611172586127), (503, 0.06221863438418041), (596, 0.07264493029754568), (597, 0.05472957306368635), (598, 0.046949655949050303), (599, 0.11885641605673786), (600, 0.06309791269365275), (601, 0.042906822358495474), (610, 0.10019681805002675), (636, 0.09056702580570611), (664, 0.02527716777225436), (687, 0.3333143419508283), (688, 0.34029170601366676), (689, 0.019381359241559152), (691, 0.39349780597052453), (694, 0.02193177744001242), (735, 0.03332285279659436), (782, 0.06768336117489085), (853, 0.02447919161589787), (902, 0.19230968739720963), (903, 0.1916218665418724), (904, 0.11829699106575324), (905, 0.4252820559954542), (908, 0.09892286858648539), (920, 0.23477970676074417), (921, 0.04001412052637377), (933, 0.15647697988394776), (934, 0.1885096836050233), (944, 0.10866571105235), (945, 0.14301969106446705), (955, 0.03449779424535203), (1025, 0.2714395373564281), (1029, 0.0414601811365727), (1032, 0.44365857403303166), (1113, 0.014712831280090337), (1152, 0.03548090956580699), (1154, 0.42219806718462344), (1159, 0.30911655917052294), (1160, 0.48360714301456015), (1161, 0.21979641304791905), (1162, 0.027384683265188926), (1163, 0.048303259696350936), (1164, 0.2995536055094963), (1165, 0.08546560504116826), (1166, 0.10969609984855237), (1168, 0.21307877205503778), (1169, 0.2540405203966453), (1170, 0.18766574504073055), (1171, 0.5131987236364155), (1172, 0.2317265740080175), (1173, 0.13455949844409038), (1174, 0.024119590315128326), (1220, 0.029281382944896548), (1237, 0.021399301675568836), (1241, 0.14602115213344055), (1252, 0.036281468668418006), (1283, 0.048724629104542706), (1292, 0.1053671821819095), (1293, 0.03722278266891147), (1301, 0.07693023196834274), (1325, 0.08087375535891726), (1340, 0.03511098166287927), (1358, 0.07972175844753336), (1379, 0.2611484854653458), (1383, 0.18518435415775514), (1414, 0.039219080202673944), (1424, 0.04339642136636022), (1463, 0.03432622810395051), (1464, 0.12819298302541907), (1481, 0.09572384725260276), (1551, 0.04895238006931308), (1554, 0.046925371166059986), (1556, 0.06314776130700323), (1569, 0.06359310743063494), (1573, 0.3570662395613138), (1574, 0.3322981907253064), (1575, 0.17980284571781993), (1576, 0.07925227996534898), (1578, 0.09998495149690814), (1582, 0.3449181612003264), (1585, 0.3235133581469967), (1619, 0.2821657824871795), (1624, 0.24500241086680985), (1646, 0.2100007799681271), (1647, 0.1217119670854253), (1668, 0.022041830065950247), (1678, 0.08558900652728565), (1686, 0.04170029691270528), (1724, 0.08575507882081587), (1756, 0.2214996972478711), (1760, 0.03004278010176865), (1761, 0.24085370050522262), (1794, 0.04340623053711324), (1849, 0.05218099204134277), (1850, 0.4799473753894587), (1854, 0.041584413561586146), (1873, 0.18849965966723684), (1957, 0.01979959692430739), (1962, 0.2920821596947521), (1963, 0.21228494329844763), (1964, 0.2367694684700238), (1965, 0.03309582986795386), (1966, 0.0518200268817153), (1967, 0.09976949296260731), (1969, 0.042657040241885054), (2009, 0.02518835281474545), (2020, 0.27863254561592765), (2023, 0.07151198514159612), (2024, 0.32093026471734115), (2025, 0.17868304526964343), (2026, 0.06610169504442592), (2048, 0.29572537718696207), (2049, 0.03536176846978188), (2052, 0.14354783111403452), (2053, 0.024442650449538833), (2054, 0.1636362742340186), (2056, 0.3814144870046556), (2057, 0.162204443989609), (2058, 0.12323367663675347), (2075, 0.31592918271951653), (2076, 0.43469886256841833), (2077, 0.1822885247903224), (2078, 0.31592918271951653), (2079, 0.10314306208925116), (2080, 0.29317183220462234), (2081, 0.1822885247903224), (2083, 0.0781911068883724), (2084, 0.3185582775240709), (2085, 0.35258844168796266), (2088, 0.340820814134253), (2089, 0.1660547369671806), (2091, 0.028889399668696813), (2092, 0.13999617398255934), (2093, 0.10033135413476223), (2094, 0.25792002055856506), (2095, 0.254024700339912), (2096, 0.18707342866806995), (2097, 0.38856589563657057), (2098, 0.2815915721635617), (2099, 0.3672401290415458), (2108, 0.031863871249676635), (2119, 0.02229546632375569), (2121, 0.02512237989962649), (2170, 0.10111202074765302), (2233, 0.1310755643746422), (2234, 0.4567092902931529), (2237, 0.072075391691934), (2238, 0.202221159342608), (2242, 0.03611229521395853), (2243, 0.18132889050847503), (2244, 0.044171507612354624), (2245, 0.04325120665251516), (2246, 0.15030549132460388), (2247, 0.050623767557015704), (2253, 0.06515267700374675), (2258, 0.15926106765400375), (2259, 0.04846889620460783), (2272, 0.38685320444530613), (2308, 0.0920122847096986), (2310, 0.31953332173663446), (2314, 0.09927169919163124), (2317, 0.11849152746247026), (2318, 0.05403906343224764), (2330, 0.13366394442136947), (2343, 0.09251495459982721), (2348, 0.047060856922430096), (2349, 0.0280031786389941), (2353, 0.2334650995333183), (2356, 0.1643596713946232), (2458, 0.14837304359428927), (2479, 0.07864317766112648), (2512, 0.35989561517251195), (2515, 0.43867553610010696), (2516, 0.05946172429027872), (2517, 0.08007462599282698), (2523, 0.21091376973152345), (2534, 0.03248233075372335), (2539, 0.04645121447131077), (2576, 0.04275956871128537), (2580, 0.04176146097667514), (2585, 0.03336921946271456), (2613, 0.02382429964552843), (2630, 0.026961404866929536), (2655, 0.19230968739720963), (2656, 0.05980122256074285), (2657, 0.41494070058639865), (2660, 0.17136158582627536), (2661, 0.05022305882091368), (2662, 0.028143063736798285), (2663, 0.14127675149356464), (2664, 0.4159488402756759), (2665, 0.09619937727327918), (2672, 0.10317168790932348), (2686, 0.035263240559981125), (2692, 0.0782527204596012), (2694, 0.22687466786699462), (2695, 0.1376208766143415), (2696, 0.3772855905391926), (2697, 0.10198867627934488), (2717, 0.15916946201325466), (2731, 0.048090722414579644), (2740, 0.10555721948101209), (2741, 0.11199128929568845), (2744, 0.0366451633407937), (2747, 0.24969103687525918), (2763, 0.03741794559922862), (2768, 0.22390133632875767), (2769, 0.26338895155522357), (2770, 0.30861870487128906), (2852, 0.028489773460305266), (2869, 0.03243184523031349), (2883, 0.08760700223043305), (2896, 0.10524589765307227), (2905, 0.03327371820792421), (2948, 0.14486718221661776), (2962, 0.02563142833159922), (2975, 0.09383423305723021), (2987, 0.08803339928979895), (3000, 0.15133131353033724), (3011, 0.02475630086067795), (3016, 0.1541610245205323), (3017, 0.18931193334523824), (3022, 0.1495056416874966), (3040, 0.3051327528134345), (3043, 0.16557051726836033), (3045, 0.3472025625492932), (3046, 0.23619381057015087), (3059, 0.1814980636217045), (3060, 0.033298665061759596), (3097, 0.34267622778336826), (3104, 0.03786053089125494), (3105, 0.23408988051262675), (3107, 0.12038657393381053), (3154, 0.07238080525427568)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Truy vấn"
      ],
      "metadata": {
        "id": "EiPU4OU1HOzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_query(path):\n",
        "    query = []\n",
        "    for doc_file in sorted(os.listdir(path),key=lambda x: int(os.path.splitext(x)[0])):\n",
        "        filename = os.path.join(path, doc_file)\n",
        "        with open(filename, encoding='utf-8', mode='r') as f:\n",
        "            temp2 = f.readlines()\n",
        "        listToStr = ' '.join([str(elem) for elem in temp2])\n",
        "        temp = \"\"\n",
        "        for i in listToStr.split():\n",
        "          content = i.replace('.', '').replace(\"''\", '').replace('\\n', '').lower()\n",
        "          content = gensim.utils.simple_preprocess(content)\n",
        "          content = [' '+non_stopword for non_stopword in content if non_stopword not in stop_words]\n",
        "          # content = [ps.stem(word) for word in content]\n",
        "          content = [lemmatizer.lemmatize(word) for word in content]\n",
        "          temp +=  \" \".join(content)\n",
        "        query.append(temp)\n",
        "    return query"
      ],
      "metadata": {
        "id": "LTbHo_Tn7tfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_res(res_path):\n",
        "      goal = []\n",
        "      for doc_file in sorted(os.listdir(res_path),key=lambda x: int(os.path.splitext(x)[0])):\n",
        "        filename = os.path.join(res_path, doc_file)\n",
        "        with open(filename, encoding='utf-8', mode='r') as f:\n",
        "            temp2 = f.readlines()\n",
        "        temp3 = []\n",
        "        a = []\n",
        "        for x in temp2:\n",
        "          a = x.strip().split()\n",
        "          for i in a:\n",
        "            temp3.append(int(i))\n",
        "        goal.append(temp3)\n",
        "      return goal"
      ],
      "metadata": {
        "id": "pG4N8T7y8aVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_search_results(query, terms, index):\n",
        "    words = get_words_from_text(query)\n",
        "\n",
        "    # Get postings\n",
        "    temp_postings = {}\n",
        "    temp_words = list(set(words))\n",
        "    for i in range(len(temp_words)):\n",
        "        if temp_words[i] in terms:\n",
        "            temp_postings[temp_words[i]] = index[terms.index(temp_words[i])].copy()\n",
        "\n",
        "    # Calculating TF * IDF (IDF = log(N / ndoc(t)))\n",
        "    N = []\n",
        "    for i in range(len(index)):\n",
        "        N.append(max(index[i],key=lambda item:item[0])[0])\n",
        "    N = max(N)\n",
        "    temp = [item for item in words if item in terms]\n",
        "    weight_list = Counter(temp)\n",
        "    weight_list = {x: weight_list[x] * math.log(N / len(temp_postings[x])) for x in weight_list}\n",
        "\n",
        "    # Normalization\n",
        "    norm = 0\n",
        "    temp = list(weight_list.values())\n",
        "    for i in range(len(temp)):\n",
        "        norm += math.pow(temp[i], 2)\n",
        "    norm = math.sqrt(norm)\n",
        "    weight_list = {x: weight_list[x] / norm for x in weight_list}\n",
        "\n",
        "    for i in temp_postings:\n",
        "        for j in range(len(temp_postings[i])):\n",
        "            temp = list(temp_postings[i][j])\n",
        "            temp[1] *= weight_list[i]\n",
        "            temp_postings[i][j] = tuple(temp)\n",
        "\n",
        "    # Get search result(s)\n",
        "    res = list(temp_postings.values())\n",
        "    result = {}\n",
        "    for L in res:\n",
        "        for key, value in L:\n",
        "            result[key] = result.get(key, 0) + value\n",
        "    result = list(result.items())\n",
        "\n",
        "    return sorted(result, key=lambda tup: tup[1], reverse=True)"
      ],
      "metadata": {
        "id": "zbPWmO5f-bUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateMAP(test_query, test_path, terms, index):\n",
        "    PRECISION = []\n",
        "    RECALL = []\n",
        "\n",
        "    query = load_query(test_query)\n",
        "    goal = load_res(test_path)\n",
        "\n",
        "    average_precision = []\n",
        "\n",
        "    for i in range(len(goal)):\n",
        "        temp4 = get_search_results(query[i], terms, index)\n",
        "        temp5 = [i[0] for i in temp4] # lấy ra danh sách các document trả về sắp xếp theo độ phù hợp giảm dần\n",
        "\n",
        "        precision = []\n",
        "        recall = []\n",
        "        count = 0\n",
        "        n = 0\n",
        "        temp_precision = []\n",
        "\n",
        "        # tính AP và recall\n",
        "        for j in range(len(temp5)):\n",
        "            if temp5[j] in goal[i]:\n",
        "                count += 1\n",
        "            n += 1\n",
        "            if (len(goal[i])==0):\n",
        "                recall.append(count / (len(goal[i])+1))\n",
        "            else:\n",
        "                recall.append(count / len(goal[i]))\n",
        "            precision.append(count / n)\n",
        "\n",
        "        # tính AP nội suy\n",
        "        temp = 0\n",
        "        for i in range(len(precision)-1, -1, -1):\n",
        "            if temp >= precision[i]:\n",
        "                precision[i] = temp\n",
        "            elif temp < precision[i]:\n",
        "                temp = precision[i]\n",
        "\n",
        "        # tính MAP 11 điểm\n",
        "        precision_list_11 = []\n",
        "        points = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "        for idx, i in enumerate(points):\n",
        "            for j in range(len(recall)):\n",
        "                if recall[j] >= i:\n",
        "                    precision_list_11.append(max(precision[j:]))\n",
        "                    break\n",
        "        if len(precision_list_11) < 11:\n",
        "          precision_list_11 += [0]*(11-len(precision_list_11))\n",
        "\n",
        "        if len(precision_list_11) != 0:\n",
        "            average_precision.append(sum(precision_list_11) / 11)\n",
        "        else:\n",
        "            average_precision.append(0)\n",
        "        PRECISION.append(precision[-1])\n",
        "        RECALL.append(recall[-1])\n",
        "    if len(average_precision) != 0:\n",
        "        return sum(average_precision) / len(average_precision), sum(PRECISION) / len(PRECISION), sum(RECALL) / len(RECALL)\n",
        "    else:\n",
        "        return 0, sum(PRECISION) / len(PRECISION), sum(RECALL) / len(RECALL)"
      ],
      "metadata": {
        "id": "9P3ZCfWY0PhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries_path = './NF_queries'\n",
        "qrel_path = './NF_qrel'"
      ],
      "metadata": {
        "id": "-Wlymh81RZgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kết quả Porter Stemmer"
      ],
      "metadata": {
        "id": "TRgsmMpVOT5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "mAP, precision, recall = evaluateMAP(queries_path, qrel_path , terms, index)\n",
        "print('mAP = ', mAP )\n",
        "print('Precision = ', precision )\n",
        "print('Recall = ', recall )\n",
        "print(\"Time: %s seconds\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfK453ES-8lw",
        "outputId": "8fab40d3-ea63-40fa-e597-1f117d390f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP =  0.005441588548039565\n",
            "Precision =  0.005829274195979898\n",
            "Recall =  0.2775801554205905\n",
            "Time: 146.23704934120178 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kết quả Lemmatizer\n"
      ],
      "metadata": {
        "id": "I3gUrUKHtMke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "mAP, precision, recall = evaluateMAP(queries_path, qrel_path , terms, index)\n",
        "print('mAP = ', mAP )\n",
        "print('Precision = ', precision )\n",
        "print('Recall = ', recall )\n",
        "print(\"Time: %s seconds\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vyt_L23OYk_",
        "outputId": "5c4954cd-8759-4e7d-aa5e-d79759a5763f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP =  0.005587448769977661\n",
            "Precision =  0.005788083139174165\n",
            "Recall =  0.2776130969402266\n",
            "Time: 148.59757709503174 seconds\n"
          ]
        }
      ]
    }
  ]
}